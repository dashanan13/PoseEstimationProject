{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.5.4.60)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.28.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.21.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.7.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.9)\n",
      "Requirement already satisfied: nose in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.7)\n",
      "Collecting Shapely\n",
      "  Downloading Shapely-1.8.0-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.28.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\devops\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: Shapely\n",
      "Successfully installed Shapely-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib\n",
    "!pip install numpy scipy matplotlib pandas sympy nose Shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Model on Lniux\n",
    "!wget -q -O lite-model_movenet_singlepose_lightning_3.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/3?lite-format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Model on Windows\n",
    "import requests\n",
    "url= \"https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/3?lite-format=tflite\"\n",
    "r= requests.get(url, allow_redirects=True)\n",
    "open('lite-model_movenet_singlepose_lightning_3.tflite', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orignal Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Rendering \n",
    "    draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "    cv2.imshow('MoveNet Lightning', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    marker_name= ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']\n",
    "    marker_count=0\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "            cv2.putText(frame, marker_name[marker_count], (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            marker_count=marker_count+1\n",
    "            \n",
    "            #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Code by Mohit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    marker_name= ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']\n",
    "    marker_count=0\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "            # put text on markers\n",
    "#             cv2.putText(frame, marker_name[marker_count], (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.putText(frame, str(marker_count), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            marker_count=marker_count+1\n",
    "            \n",
    "            #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List camera devices\n",
    "\n",
    "index = 0\n",
    "arr = []\n",
    "while True:\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    if not cap.read()[0]:\n",
    "        break\n",
    "    else:\n",
    "        arr.append(index)\n",
    "    cap.release()\n",
    "    index += 1\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make Detections - Mohit Version for black screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    \n",
    "    #width, height = img.size\n",
    "    #print(width, height)\n",
    "    \n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192, 192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    #Rendering with background image \n",
    "    \n",
    "    #Reading the background image\n",
    "    image = cv2.imread(r'C:\\Users\\devops\\PoseEstimationProject\\background.jpg')\n",
    "    width = 800\n",
    "    height = 1100\n",
    "    dim = (width, height)\n",
    "    image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    #Create a black image\n",
    "    img = np.zeros((512,512,3), np.uint8)\n",
    "    \n",
    "    draw_connections(image, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(image, keypoints_with_scores, 0.4)\n",
    "        \n",
    "    cv2.imshow('MoveNet Lightning', image)\n",
    "    \n",
    "#     # Rendering \n",
    "#     draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "#     draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "#     cv2.imshow('MoveNet Lightning', frame)\n",
    "        \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update image with another sub image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import cv2\n",
    "\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq\n",
    "import math\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get line equation from 2 points on the line\n",
    "def get_squareCorners(x1, y1, x2, y2):\n",
    "    \n",
    "    line_length = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress([x1,x2],[y1,y2])\n",
    "    \n",
    "    a = (x1, y1)\n",
    "    b = (x2, y2)\n",
    "    ab = LineString([a, b])\n",
    "    left = ab.parallel_offset(line_length / 2, 'left')\n",
    "    right = ab.parallel_offset(line_length / 2, 'right')\n",
    "    \n",
    "    c = left.boundary[1]\n",
    "    d = right.boundary[0]\n",
    "    e = left.boundary[0]\n",
    "    f = right.boundary[1]\n",
    "    \n",
    "    print(slope,intercept)\n",
    "    return (c, d, e, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "points are:\n",
      "[[ 6.  1.]\n",
      " [ 6. -1.]\n",
      " [ 4.  1.]\n",
      " [ 4. -1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devops\\AppData\\Local\\Temp/ipykernel_6896/2126112649.py:13: ShapelyDeprecationWarning: __getitem__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  c = left.boundary[1]\n",
      "C:\\Users\\devops\\AppData\\Local\\Temp/ipykernel_6896/2126112649.py:14: ShapelyDeprecationWarning: __getitem__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  d = right.boundary[0]\n",
      "C:\\Users\\devops\\AppData\\Local\\Temp/ipykernel_6896/2126112649.py:15: ShapelyDeprecationWarning: __getitem__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  e = left.boundary[0]\n",
      "C:\\Users\\devops\\AppData\\Local\\Temp/ipykernel_6896/2126112649.py:16: ShapelyDeprecationWarning: __getitem__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  f = right.boundary[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c, d, e, f = get_squareCorners(4, 0, 6, 0)\n",
    "points = np.array(\n",
    "[\n",
    "    [c.x, c.y],\n",
    "    [d.x, d.y],\n",
    "    [e.x, e.y],\n",
    "    [f.x, f.y],\n",
    "])\n",
    "print(\"points are:\")\n",
    "print(points)\n",
    "plt.plot([4,6], [0,0], color = 'blue')\n",
    "plt.plot([c.x, d.x], [c.y,d.y], color='red')\n",
    "plt.plot([e.x, f.x], [e.y,f.y], color = 'black')\n",
    "plt.plot([c.x, e.x], [c.y,e.y], color='yellow')\n",
    "plt.plot([d.x, f.x], [d.y,f.y], color = 'green')\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "horizontal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "slope,intercept = get_linequation(0, 0, 0, 100)\n",
    "\n",
    "if(math.isnan(slope)):\n",
    "    print('horizontal')\n",
    "\n",
    "plt.plot([0,0], [0,100])\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get coordinated of the square which has these 2 points on opposite edges in middle of those edges\n",
    "#===============================================================\n",
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    marker_name= ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']\n",
    "    marker_count=0\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "            # put text on markers\n",
    "#             cv2.putText(frame, str(str(int(kx)) + ',' + str(int(kx))), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.putText(frame, marker_name[marker_count], (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "#             cv2.putText(frame, str(marker_count), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            marker_count=marker_count+1\n",
    "            if (marker_name[marker_count] == 'left ear'):\n",
    "                print('left eye: ' + (str(kx) + ',' + str(ky)))\n",
    "            if (marker_name[marker_count] == 'right ear'):\n",
    "                print('right eye: ' + (str(kx) + ',' + str(ky)))\n",
    "            #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "#============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    marker_name= ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']\n",
    "    marker_count=0\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "            # put text on markers\n",
    "#             cv2.putText(frame, str(str(int(kx)) + ',' + str(int(kx))), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.putText(frame, marker_name[marker_count], (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "#             cv2.putText(frame, str(marker_count), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            marker_count=marker_count+1\n",
    "            if (marker_name[marker_count] == 'left ear'):\n",
    "                print('left eye: ' + (str(kx) + ',' + str(ky)))\n",
    "            if (marker_name[marker_count] == 'right ear'):\n",
    "                print('right eye: ' + (str(kx) + ',' + str(ky)))\n",
    "            #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "            \n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headimg = cv2.imread(r'C:\\Users\\devops\\PoseEstimationProject\\head.jpg', cv2.IMREAD_COLOR)\n",
    "headimg= cv2.cvtColor(headimg, cv2.COLOR_BGR2RGB)\n",
    "print(headimg.shape)\n",
    "plt.imshow(headimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    \n",
    "    #width, height = img.size\n",
    "    #print(width, height)\n",
    "    \n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192, 192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    #Rendering with background image, using black image\n",
    "    img = np.zeros((512,512,3), np.uint8)\n",
    "    \n",
    "    draw_connections(img, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(img, keypoints_with_scores, 0.4)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    cv2.imshow('MoveNet Lightning', img)\n",
    "    \n",
    "#     # Rendering \n",
    "#     draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "#     draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "#     cv2.imshow('MoveNet Lightning', frame)\n",
    "        \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
