{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib\n",
    "!pip install numpy scipy matplotlib pandas sympy nose Shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Model on Lniux\n",
    "!wget -q -O lite-model_movenet_singlepose_lightning_3.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/3?lite-format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Model on Windows\n",
    "import requests\n",
    "url= \"https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/3?lite-format=tflite\"\n",
    "r= requests.get(url, allow_redirects=True)\n",
    "open('lite-model_movenet_singlepose_lightning_3.tflite', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orignal Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Rendering \n",
    "    draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "    cv2.imshow('MoveNet Lightning', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    marker_name= ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']\n",
    "    marker_count=0\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "            cv2.putText(frame, marker_name[marker_count], (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            marker_count=marker_count+1\n",
    "            \n",
    "            #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Code by Mohit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    marker_name= ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']\n",
    "    marker_count=0\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "            # put text on markers\n",
    "#             cv2.putText(frame, marker_name[marker_count], (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.putText(frame, str(marker_count), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "            marker_count=marker_count+1\n",
    "            \n",
    "            #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List camera devices\n",
    "\n",
    "index = 0\n",
    "arr = []\n",
    "while True:\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    if not cap.read()[0]:\n",
    "        break\n",
    "    else:\n",
    "        arr.append(index)\n",
    "    cap.release()\n",
    "    index += 1\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make Detections - Mohit Version for black screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    \n",
    "    #width, height = img.size\n",
    "    #print(width, height)\n",
    "    \n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192, 192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    #Rendering with background image \n",
    "    \n",
    "    #Reading the background image\n",
    "    image = cv2.imread(r'C:\\Users\\devops\\PoseEstimationProject\\background.jpg')\n",
    "    width = 800\n",
    "    height = 1100\n",
    "    dim = (width, height)\n",
    "    image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    #Create a black image\n",
    "    img = np.zeros((512,512,3), np.uint8)\n",
    "    \n",
    "    draw_connections(image, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(image, keypoints_with_scores, 0.4)\n",
    "        \n",
    "    cv2.imshow('MoveNet Lightning', image)\n",
    "    \n",
    "#     # Rendering \n",
    "#     draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "#     draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "#     cv2.imshow('MoveNet Lightning', frame)\n",
    "        \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update image with another sub image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import cv2\n",
    "\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq\n",
    "import math\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get corners of a square with only the coordinates of the line in middle\n",
    "def get_quadCorners(x1, y1, x2, y2, factor):\n",
    "    \n",
    "#     print(\"Passing to Fn: \" + str(x1) + \", \" + str(x2) + \", \" + str(y1) + \", \" + str(y2))\n",
    "    line_length = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress([x1,x2],[y1,y2])\n",
    "    \n",
    "    a = (x1, y1)\n",
    "    b = (x2, y2)\n",
    "    ab = LineString([a, b])\n",
    "    left = ab.parallel_offset(line_length / int(factor), 'left')\n",
    "    right = ab.parallel_offset(line_length / int(factor), 'right')\n",
    "    \n",
    "    c = left.boundary[1]\n",
    "    d = right.boundary[0]\n",
    "    e = left.boundary[0]\n",
    "    f = right.boundary[1]\n",
    "    \n",
    "    points = np.array(\n",
    "    [\n",
    "        [c.x, c.y],\n",
    "        [d.x, d.y],\n",
    "        [e.x, e.y],\n",
    "        [f.x, f.y],\n",
    "    ])\n",
    "    \n",
    "#     print(slope,intercept)\n",
    "    return (points)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = [[4,0], [6,0]]   # point definition\n",
    "squareCorners = get_quadCorners(a[0], a[1], b[0], b[1], 2)\n",
    "\n",
    "plt.plot([a[0],b[0]], [a[1],b[1]], color = 'blue')\n",
    "plt.plot([squareCorners[0][0], squareCorners[1][0]], [squareCorners[0][1], squareCorners[1][1]], color='red')\n",
    "plt.plot([squareCorners[0][0], squareCorners[2][0]], [squareCorners[0][1], squareCorners[2][1]], color='yellow')\n",
    "plt.plot([squareCorners[2][0], squareCorners[3][0]], [squareCorners[2][1], squareCorners[3][1]], color='black')\n",
    "plt.plot([squareCorners[1][0], squareCorners[3][0]], [squareCorners[1][1], squareCorners[3][1]], color='green')\n",
    "\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_keypoints_withnames:\n",
    "  def __init__(self, x, y, confidence, name):\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    self.confidence = confidence\n",
    "    self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_name = ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']  \n",
    "count = 0\n",
    "for m in marker_name:\n",
    "    print(str(count) + \": \" + m)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoints_modification(frame, keypoints):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    shaped_modified = np.empty(shape=(53, 4), dtype=all_keypoints_withnames)\n",
    "    \n",
    "    marker_name = ['nose', 'left eye','right eye', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'left elbow', 'right elbow', 'left wrist','right wrist', 'left hip', 'right hip', 'left knee', 'right knee', 'left ankle', 'right ankle']  \n",
    "    marker_count = 0\n",
    "    leg_factor= 3\n",
    "    hand_factor= 4\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        \n",
    "        shaped_modified[marker_count] = [ky, kx, kp_conf, marker_name[marker_count]]  # getting new keypoints array populated with inital points            \n",
    "        marker_count=marker_count+1\n",
    "\n",
    "    # Custom points displayed and added in the list for FACE square\n",
    "    squareCorners = get_quadCorners(shaped_modified[3][1], shaped_modified[3][0], shaped_modified[4][1], shaped_modified[4][0], 2)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[17] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[3][2], \"face top right\"] \n",
    "    shaped_modified[18] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[3][2], \"face bottom right\"]\n",
    "    shaped_modified[19] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[3][2], \"face top left\"]\n",
    "    shaped_modified[20] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[3][2], \"face bottom left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for left bicep rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[5][1], shaped_modified[5][0], shaped_modified[7][1], shaped_modified[7][0], hand_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[21] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[5][2], \"left bicep bottom right\"] \n",
    "    shaped_modified[22] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[5][2], \"left bicep bottom left\"]\n",
    "    shaped_modified[23] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[5][2], \"left bicep top right\"]\n",
    "    shaped_modified[24] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[5][2], \"left bicep top left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for left forearm rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[7][1], shaped_modified[7][0], shaped_modified[9][1], shaped_modified[9][0], hand_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[25] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[7][2], \"left forearm bottom right\"] \n",
    "    shaped_modified[26] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[7][2], \"left forearm bottom left\"]\n",
    "    shaped_modified[27] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[7][2], \"left forearm top right\"]\n",
    "    shaped_modified[28] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[7][2], \"left forearm top left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for right bicep rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[6][1], shaped_modified[6][0], shaped_modified[8][1], shaped_modified[8][0], hand_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[29] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[6][2], \"right bicep bottom right\"] \n",
    "    shaped_modified[30] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[6][2], \"right bicep bottom left\"]\n",
    "    shaped_modified[31] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[6][2], \"right bicep top right\"]\n",
    "    shaped_modified[32] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[6][2], \"right bicep top left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for right forearm rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[8][1], shaped_modified[8][0], shaped_modified[10][1], shaped_modified[10][0], hand_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[33] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[8][2], \"right forearm bottom right\"] \n",
    "    shaped_modified[34] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[8][2], \"right forearm bottom left\"]\n",
    "    shaped_modified[35] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[8][2], \"right forearm top right\"]\n",
    "    shaped_modified[36] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[8][2], \"right forearm top left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for left thigh rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[11][1], shaped_modified[11][0], shaped_modified[13][1], shaped_modified[13][0], leg_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[37] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[11][2], \"left thigh bottom right\"] \n",
    "    shaped_modified[38] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[11][2], \"left thigh bottom left\"]\n",
    "    shaped_modified[39] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[11][2], \"left thigh top right\"]\n",
    "    shaped_modified[40] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[11][2], \"left thigh top left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for left calf rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[13][1], shaped_modified[13][0], shaped_modified[15][1], shaped_modified[15][0], leg_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[41] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[13][2], \"left calf bottom right\"] \n",
    "    shaped_modified[42] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[13][2], \"left calf bottom left\"]\n",
    "    shaped_modified[43] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[13][2], \"left calf top right\"]\n",
    "    shaped_modified[44] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[13][2], \"left calf top left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for right thigh rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[12][1], shaped_modified[12][0], shaped_modified[14][1], shaped_modified[14][0], leg_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[45] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[12][2], \"right thigh bottom right\"] \n",
    "    shaped_modified[46] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[12][2], \"right thigh bottom left\"]\n",
    "    shaped_modified[47] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[12][2], \"right thigh top right\"]\n",
    "    shaped_modified[48] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[12][2], \"right thigh top left\"]\n",
    "\n",
    "    # Custom points displayed and added in the list for right calf rectangle\n",
    "    squareCorners = get_quadCorners(shaped_modified[14][1], shaped_modified[14][0], shaped_modified[16][1], shaped_modified[16][0], leg_factor)\n",
    "    # Adding new keypoints for face square\n",
    "    shaped_modified[49] = [squareCorners[0][1], squareCorners[0][0], shaped_modified[14][2], \"right calf bottom right\"] \n",
    "    shaped_modified[50] = [squareCorners[1][1], squareCorners[1][0], shaped_modified[14][2], \"right calf bottom left\"]\n",
    "    shaped_modified[51] = [squareCorners[2][1], squareCorners[2][0], shaped_modified[14][2], \"right calf top right\"]\n",
    "    shaped_modified[52] = [squareCorners[3][1], squareCorners[3][0], shaped_modified[14][2], \"right calf top left\"]\n",
    "\n",
    "#     print((shaped_modified))\n",
    "#     count = 0\n",
    "#     for sm in shaped_modified:\n",
    "#         print(str(count) + \": \" + str(sm[3]))\n",
    "#         count = count + 1 \n",
    "    return shaped_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    \n",
    "    marker_count = 0\n",
    "    \n",
    "    for kp in keypoints:\n",
    "        ky, kx, kp_conf, kp_name = kp\n",
    "        \n",
    "        if kp_conf > confidence_threshold:\n",
    "#             if (not (marker_count in list(range(17)))):\n",
    "            if(marker_count in [17,18,19,20]):\n",
    "                cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) \n",
    "                # put text on markers\n",
    "                cv2.putText(frame, str(kp_name), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "#             cv2.putText(frame, str(str(int(kx)) + ',' + str(int(kx))), (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "#             cv2.putText(frame, marker_name[marker_count], (int(kx), int(ky)), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "        marker_count=marker_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myframe = cv2.imread(r'C:\\Users\\devops\\PoseEstimationProject\\fb1.jpeg')\n",
    "# plt.imshow(myframe)\n",
    "img = myframe.copy()\n",
    "new_keypoints = keypoints_modification(frame, keypoints_with_scores)\n",
    "draw_keypoints(img, new_keypoints, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_EDGES = {\n",
    "    (17, 18): 'm',\n",
    "    (18, 20): 'c',\n",
    "    (20, 19): 'm',\n",
    "    (17, 19): 'c',\n",
    "    (18, 6): 'm',\n",
    "    (20, 5): 'c',\n",
    "    (5, 6): 'm',\n",
    "    (5, 40): 'm',\n",
    "    (6, 47): 'c',\n",
    "    (40, 47): 'c',\n",
    "    \n",
    "    (23, 24): 'y',\n",
    "    (21, 22): 'm',\n",
    "    (22, 24): 'c',\n",
    "    (21, 23): 'y',    \n",
    "    (25, 26): 'm',\n",
    "    (27, 28): 'm',\n",
    "    (25, 27): 'c',\n",
    "    (26, 28): 'c',\n",
    "    \n",
    "    (29, 30): 'y',\n",
    "    (31, 32): 'm',\n",
    "    (29, 31): 'c',\n",
    "    (30, 32): 'y',\n",
    "    (33, 34): 'm',\n",
    "    (35, 36): 'm',\n",
    "    (33, 35): 'c',\n",
    "    (34, 36): 'c',\n",
    "\n",
    "    (37, 38): 'y',\n",
    "    (39, 40): 'm',\n",
    "    (37, 39): 'c',\n",
    "    (38, 40): 'y',\n",
    "    (41, 42): 'm',\n",
    "    (43, 44): 'm',\n",
    "    (41, 43): 'c',\n",
    "    (42, 44): 'c',\n",
    "    \n",
    "    (45, 46): 'y',\n",
    "    (47, 48): 'm',\n",
    "    (45, 47): 'c',\n",
    "    (46, 48): 'y',\n",
    "    (49, 50): 'm',\n",
    "    (51, 52): 'm',\n",
    "    (49, 51): 'c',\n",
    "    (50, 52): 'c',\n",
    "}\n",
    "        \n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1, n1 = keypoints[p1]\n",
    "        y2, x2, c2, n2 = keypoints[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headimg = cv2.imread(r'C:\\Users\\devops\\PoseEstimationProject\\head.jpg', cv2.IMREAD_COLOR)\n",
    "headimg= cv2.cvtColor(headimg, cv2.COLOR_BGR2RGB)\n",
    "print(headimg.shape)\n",
    "plt.imshow(headimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myframe = cv2.imread(r'C:\\Users\\devops\\PoseEstimationProject\\fb1.jpeg')\n",
    "plt.imshow(myframe)\n",
    "img = myframe.copy()\n",
    "draw_keypoints(img, keypoints_with_scores, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    \n",
    "    #width, height = img.size\n",
    "    #print(width, height)\n",
    "    \n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192, 192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "#     #Rendering with background image, using black image\n",
    "#     img = np.zeros((512,512,3), np.uint8)\n",
    "    \n",
    "#     draw_connections(img, keypoints_with_scores, EDGES, 0.4)\n",
    "#     draw_keypoints(img, keypoints_with_scores, 0.4)\n",
    "#     keypoints_modification(frame, keypoints_with_scores)\n",
    "\n",
    "#     cv2.imshow('MoveNet Lightning', img)\n",
    "    \n",
    "    # Rendering with orignal frame\n",
    "#     draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "#     draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "\n",
    "    new_keypoints = keypoints_modification(frame, keypoints_with_scores)\n",
    "    \n",
    "    draw_connections(frame, new_keypoints, BOX_EDGES, 0.4)\n",
    "    draw_keypoints(frame, new_keypoints, 0.4)\n",
    "    \n",
    "    cv2.imshow('MoveNet Lightning', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
